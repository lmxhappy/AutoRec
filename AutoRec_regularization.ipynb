{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0jM2Mq4akyFG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jM2Mq4akyFG",
        "outputId": "1b5e99be-a5c8-4f25-b916-7e5d07a212c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 34.0 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 69.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.3 MB 12 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchdata) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.6.15)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Installing collected packages: urllib3, torch, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\n",
            "Successfully installed portalocker-2.5.1 torch-1.12.1 torchdata-0.4.1 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3GbcZ0PAkoc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GbcZ0PAkoc6",
        "outputId": "f9087223-1ba2-43b7-eb33-a3b8b3292368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-07 12:43:01--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  2.92MB/s    in 1.9s    \n",
            "\n",
            "2022-08-07 12:43:04 (2.92 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ]
        }
      ],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3ca85530-54da-4a45-bf76-18549c7bc18b",
      "metadata": {
        "id": "3ca85530-54da-4a45-bf76-18549c7bc18b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, div, square, norm\n",
        "from torch.nn import functional as F\n",
        "from torchdata import datapipes as dp\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fa37b148-81c0-4c5f-8f91-5c826a2e1132",
      "metadata": {
        "id": "fa37b148-81c0-4c5f-8f91-5c826a2e1132"
      },
      "outputs": [],
      "source": [
        "datapath = 'ml-1m/'\n",
        "seed = 12\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "432aa6bd-69e6-49bc-be63-e2b2f131cc2f",
      "metadata": {
        "id": "432aa6bd-69e6-49bc-be63-e2b2f131cc2f"
      },
      "outputs": [],
      "source": [
        "num_users = pd.read_csv(datapath + 'users.dat',\n",
        "            delimiter='::',\n",
        "            engine='python',\n",
        "            encoding='latin-1',\n",
        "            header=None)[0].max()\n",
        "num_items = pd.read_csv(datapath + 'movies.dat',\n",
        "            delimiter='::',\n",
        "            engine='python',\n",
        "            encoding='latin-1',\n",
        "            header=None)[0].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "adc1f682-19c6-4958-8c24-c320138b3c38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adc1f682-19c6-4958-8c24-c320138b3c38",
        "outputId": "7bed8bd0-567c-4896-a1f3-017942cbde55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6040, 3952)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_users, num_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "841c738c-bc2f-4203-9c3a-e21b4aaa271c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "841c738c-bc2f-4203-9c3a-e21b4aaa271c",
        "outputId": "a505d489-cd5b-4edb-af1f-84254c35c1b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3161]), torch.Size([791]))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_items, test_items = train_test_split(torch.arange(num_items),\n",
        "                                           test_size=0.2,\n",
        "                                           random_state=seed)\n",
        "train_items.size(), test_items.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5eb081cd-a018-4171-8dee-27f91be9ae0e",
      "metadata": {
        "id": "5eb081cd-a018-4171-8dee-27f91be9ae0e"
      },
      "outputs": [],
      "source": [
        "# create global user_item matrix and mask matrix\n",
        "user_item_mat = torch.zeros((num_users, num_items))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6cb1e617-274f-44c2-9e3b-5a9e445fed60",
      "metadata": {
        "id": "6cb1e617-274f-44c2-9e3b-5a9e445fed60"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv(datapath + 'ratings.dat',\n",
        "            encoding='latin-1',\n",
        "            header=None,\n",
        "            engine='python',\n",
        "            delimiter='::')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dbfe69d5-876f-470b-baaa-c715b0ed7f1f",
      "metadata": {
        "id": "dbfe69d5-876f-470b-baaa-c715b0ed7f1f"
      },
      "outputs": [],
      "source": [
        "def create_data_from_line(line):\n",
        "    user_id, item_id, rating, *_ = line\n",
        "    user_item_mat[user_id - 1, item_id - 1] = rating\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f1f1c70c-4faf-4333-9ce3-4edae844a7c1",
      "metadata": {
        "id": "f1f1c70c-4faf-4333-9ce3-4edae844a7c1"
      },
      "outputs": [],
      "source": [
        "ratings.T.apply(create_data_from_line);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b8908844-5f9a-415f-9b15-d1330c8abdae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8908844-5f9a-415f-9b15-d1330c8abdae",
        "outputId": "7ae5cf2a-05c8-4b28-9f64-906d29fb486c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9581)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.where(user_item_mat == 0, 1, 0).sum() / (num_users * num_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2d1b5e0b-614b-43a9-b536-cad62642a39a",
      "metadata": {
        "id": "2d1b5e0b-614b-43a9-b536-cad62642a39a"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return torch.LongTensor(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b85b6d39-3de5-42fd-a7e5-c31f0542321a",
      "metadata": {
        "id": "b85b6d39-3de5-42fd-a7e5-c31f0542321a"
      },
      "outputs": [],
      "source": [
        "def create_datapipe_from_array(array, mode='train', batch_size=32, len=1000):\n",
        "    pipes = dp.iter.IterableWrapper(array)\n",
        "    pipes = pipes.shuffle(buffer_size=len)\n",
        "    pipes = pipes.sharding_filter()\n",
        "    \n",
        "    if mode == 'train':\n",
        "        pipes = pipes.batch(batch_size, drop_last=True)\n",
        "    else:\n",
        "        pipes = pipes.batch(batch_size)\n",
        "    \n",
        "    pipes = pipes.map(collate_fn)\n",
        "    return pipes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f4466bc0-38bb-49ae-b5b9-8599aa3b93af",
      "metadata": {
        "id": "f4466bc0-38bb-49ae-b5b9-8599aa3b93af"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_dp = create_datapipe_from_array(train_items, batch_size=batch_size)\n",
        "test_dp = create_datapipe_from_array(test_items, mode='test', batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3c39eebc-f565-401e-b28f-eed5b07a2877",
      "metadata": {
        "id": "3c39eebc-f565-401e-b28f-eed5b07a2877"
      },
      "outputs": [],
      "source": [
        "num_workers = 2\n",
        "\n",
        "train_dl = DataLoader(dataset=train_dp, shuffle=True, num_workers=num_workers)\n",
        "test_dl = DataLoader(dataset=test_dp, shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "680914e1-62ca-4ca5-b7c8-55c3f2fbf5fa",
      "metadata": {
        "id": "680914e1-62ca-4ca5-b7c8-55c3f2fbf5fa"
      },
      "outputs": [],
      "source": [
        "class AutoRec(nn.Module):\n",
        "    def __init__(self, d, k, lambda_):\n",
        "        super().__init__()\n",
        "        self.lambda_ = lambda_\n",
        "        self.W = nn.Parameter(torch.randn(d, k))\n",
        "        self.V = nn.Parameter(torch.randn(k, d))\n",
        "        self.mu = nn.Parameter(torch.randn(k))\n",
        "        self.b = nn.Parameter(torch.randn(d))\n",
        "    \n",
        "    def regularization(self):\n",
        "        return div(self.lambda_, 2) * (square(norm(self.W)) + square(norm(self.V)))\n",
        "    \n",
        "    def forward(self, r):\n",
        "        encoder = self.V.matmul(r.T).T + self.mu\n",
        "        return self.W.matmul(encoder.sigmoid().T).T + self.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "644d28f2-dc09-40f1-b0c9-ffb7df93c0fc",
      "metadata": {
        "id": "644d28f2-dc09-40f1-b0c9-ffb7df93c0fc"
      },
      "outputs": [],
      "source": [
        "def autorec_loss(r, r_hat):\n",
        "    return F.mse_loss(r, r_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "44c533de-1f35-435d-abf4-92d8b2b66fea",
      "metadata": {
        "id": "44c533de-1f35-435d-abf4-92d8b2b66fea"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dl, opt, criterion):\n",
        "    list_loss = []\n",
        "    start_time = time.perf_counter()\n",
        "    for batch_idx, items_idx in enumerate(dl):\n",
        "        r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device)\n",
        "        r_hat = model(r)\n",
        "        loss = criterion(r, r_hat * torch.sign(r))\n",
        "        \n",
        "        list_loss.append(loss.item())\n",
        "        if batch_idx % 50 == 0:\n",
        "            log_time = round(time.perf_counter() - start_time, 4)\n",
        "            print(\"Loss {:.2f} | {:.4f}s\".format(loss.item(), log_time))\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return list_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9cab2f4a-52d2-4681-a6c8-6d7699084c41",
      "metadata": {
        "id": "9cab2f4a-52d2-4681-a6c8-6d7699084c41"
      },
      "outputs": [],
      "source": [
        "def eval_epoch(model, dl, criterion):\n",
        "    model.eval()\n",
        "    truth = []\n",
        "    predict = []\n",
        "    size = 0\n",
        "    list_loss = []\n",
        "    start_time = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, items_idx in enumerate(dl):\n",
        "            r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device)\n",
        "\n",
        "            r_hat = model(r)\n",
        "\n",
        "            truth.append(r)\n",
        "            predict.append(r_hat * torch.sign(r))\n",
        "\n",
        "            loss = criterion(r, r_hat * torch.sign(r))\n",
        "\n",
        "            list_loss.append(loss.item())\n",
        "            if batch_idx % 30 == 0:\n",
        "                log_time = round(time.perf_counter() - start_time, 4)\n",
        "                print(\"Loss {:.2f} | {:.4f}s\".format(loss.item(), log_time))\n",
        "\n",
        "    rmse = torch.Tensor([torch.sqrt(square(r - r_hat).sum() / torch.sign(r).sum())\n",
        "                            for r, r_hat in zip(truth, predict)]).mean().item()\n",
        "\n",
        "    return list_loss, rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "d42ef645-20e3-4419-aadb-68125fc6acf4",
      "metadata": {
        "id": "d42ef645-20e3-4419-aadb-68125fc6acf4"
      },
      "outputs": [],
      "source": [
        "model = AutoRec(d=num_users, k=500, lambda_=1).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
        "criterion = nn.MSELoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "c1-EWBorMNCz",
      "metadata": {
        "id": "c1-EWBorMNCz"
      },
      "outputs": [],
      "source": [
        "max_epochs = 100\n",
        "losses = []\n",
        "val_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3802be9b-add0-463c-afac-e9657fd43076",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3802be9b-add0-463c-afac-e9657fd43076",
        "outputId": "37f14262-ba47-4757-ccf5-c4f7b35f68ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========Epoch: 0==========\n",
            "Loss 11.51 | 0.1910s\n",
            "Loss 4.07 | 0.1339s\n",
            "==========Epoch: 1==========\n",
            "Loss 3.58 | 0.2000s\n",
            "Loss 2.76 | 0.1324s\n",
            "==========Epoch: 2==========\n",
            "Loss 2.66 | 0.1889s\n",
            "Loss 1.99 | 0.1381s\n",
            "==========Epoch: 3==========\n",
            "Loss 1.88 | 0.1892s\n",
            "Loss 1.48 | 0.1348s\n",
            "==========Epoch: 4==========\n",
            "Loss 1.39 | 0.1849s\n",
            "Loss 1.11 | 0.1389s\n",
            "==========Epoch: 5==========\n",
            "Loss 1.05 | 0.1858s\n",
            "Loss 0.84 | 0.1281s\n",
            "==========Epoch: 6==========\n",
            "Loss 0.78 | 0.1991s\n",
            "Loss 0.66 | 0.1314s\n",
            "==========Epoch: 7==========\n",
            "Loss 0.58 | 0.1854s\n",
            "Loss 0.53 | 0.1359s\n",
            "==========Epoch: 8==========\n",
            "Loss 0.47 | 0.1862s\n",
            "Loss 0.44 | 0.1296s\n",
            "==========Epoch: 9==========\n",
            "Loss 0.36 | 0.1787s\n",
            "Loss 0.37 | 0.1335s\n",
            "==========Epoch: 10==========\n",
            "Loss 0.30 | 0.1867s\n",
            "Loss 0.32 | 0.1359s\n",
            "==========Epoch: 11==========\n",
            "Loss 0.26 | 0.1848s\n",
            "Loss 0.29 | 0.1338s\n",
            "==========Epoch: 12==========\n",
            "Loss 0.22 | 0.1858s\n",
            "Loss 0.26 | 0.1303s\n",
            "==========Epoch: 13==========\n",
            "Loss 0.21 | 0.1912s\n",
            "Loss 0.24 | 0.1319s\n",
            "==========Epoch: 14==========\n",
            "Loss 0.18 | 0.1823s\n",
            "Loss 0.22 | 0.1358s\n",
            "==========Epoch: 15==========\n",
            "Loss 0.16 | 0.1806s\n",
            "Loss 0.21 | 0.1387s\n",
            "==========Epoch: 16==========\n",
            "Loss 0.15 | 0.1891s\n",
            "Loss 0.20 | 0.1330s\n",
            "==========Epoch: 17==========\n",
            "Loss 0.13 | 0.1942s\n",
            "Loss 0.19 | 0.1276s\n",
            "==========Epoch: 18==========\n",
            "Loss 0.12 | 0.1951s\n",
            "Loss 0.18 | 0.1429s\n",
            "==========Epoch: 19==========\n",
            "Loss 0.11 | 0.1908s\n",
            "Loss 0.17 | 0.1346s\n",
            "==========Epoch: 20==========\n",
            "Loss 0.11 | 0.1806s\n",
            "Loss 0.16 | 0.1337s\n",
            "==========Epoch: 21==========\n",
            "Loss 0.11 | 0.1787s\n",
            "Loss 0.16 | 0.1373s\n",
            "==========Epoch: 22==========\n",
            "Loss 0.10 | 0.1807s\n",
            "Loss 0.15 | 0.1299s\n",
            "==========Epoch: 23==========\n",
            "Loss 0.09 | 0.1987s\n",
            "Loss 0.15 | 0.1390s\n",
            "==========Epoch: 24==========\n",
            "Loss 0.09 | 0.1835s\n",
            "Loss 0.14 | 0.1341s\n",
            "==========Epoch: 25==========\n",
            "Loss 0.09 | 0.1797s\n",
            "Loss 0.14 | 0.1420s\n",
            "==========Epoch: 26==========\n",
            "Loss 0.08 | 0.1928s\n",
            "Loss 0.14 | 0.1347s\n",
            "==========Epoch: 27==========\n",
            "Loss 0.08 | 0.1802s\n",
            "Loss 0.13 | 0.1428s\n",
            "==========Epoch: 28==========\n",
            "Loss 0.08 | 0.1877s\n",
            "Loss 0.13 | 0.1374s\n",
            "==========Epoch: 29==========\n",
            "Loss 0.07 | 0.2009s\n",
            "Loss 0.12 | 0.1414s\n",
            "==========Epoch: 30==========\n",
            "Loss 0.07 | 0.1844s\n",
            "Loss 0.12 | 0.1428s\n",
            "==========Epoch: 31==========\n",
            "Loss 0.07 | 0.1839s\n",
            "Loss 0.12 | 0.1375s\n",
            "==========Epoch: 32==========\n",
            "Loss 0.07 | 0.1985s\n",
            "Loss 0.11 | 0.1323s\n",
            "==========Epoch: 33==========\n",
            "Loss 0.07 | 0.1807s\n",
            "Loss 0.11 | 0.1398s\n",
            "==========Epoch: 34==========\n",
            "Loss 0.07 | 0.1870s\n",
            "Loss 0.11 | 0.1319s\n",
            "==========Epoch: 35==========\n",
            "Loss 0.06 | 0.1876s\n",
            "Loss 0.11 | 0.1330s\n",
            "==========Epoch: 36==========\n",
            "Loss 0.06 | 0.1799s\n",
            "Loss 0.10 | 0.1388s\n",
            "==========Epoch: 37==========\n",
            "Loss 0.06 | 0.1863s\n",
            "Loss 0.10 | 0.1355s\n",
            "==========Epoch: 38==========\n",
            "Loss 0.06 | 0.1861s\n",
            "Loss 0.10 | 0.1381s\n",
            "==========Epoch: 39==========\n",
            "Loss 0.06 | 0.1995s\n",
            "Loss 0.10 | 0.1416s\n",
            "==========Epoch: 40==========\n",
            "Loss 0.06 | 0.1890s\n",
            "Loss 0.09 | 0.1369s\n",
            "==========Epoch: 41==========\n",
            "Loss 0.06 | 0.1783s\n",
            "Loss 0.09 | 0.1364s\n",
            "==========Epoch: 42==========\n",
            "Loss 0.06 | 0.1794s\n",
            "Loss 0.09 | 0.1334s\n",
            "==========Epoch: 43==========\n",
            "Loss 0.05 | 0.1860s\n",
            "Loss 0.09 | 0.1332s\n",
            "==========Epoch: 44==========\n",
            "Loss 0.06 | 0.1894s\n",
            "Loss 0.09 | 0.1382s\n",
            "==========Epoch: 45==========\n",
            "Loss 0.06 | 0.1823s\n",
            "Loss 0.08 | 0.1390s\n",
            "==========Epoch: 46==========\n",
            "Loss 0.05 | 0.1862s\n",
            "Loss 0.08 | 0.1337s\n",
            "==========Epoch: 47==========\n",
            "Loss 0.05 | 0.1831s\n",
            "Loss 0.08 | 0.1439s\n",
            "==========Epoch: 48==========\n",
            "Loss 0.05 | 0.1841s\n",
            "Loss 0.08 | 0.1406s\n",
            "==========Epoch: 49==========\n",
            "Loss 0.05 | 0.1897s\n",
            "Loss 0.08 | 0.1377s\n",
            "==========Epoch: 50==========\n",
            "Loss 0.05 | 0.1834s\n",
            "Loss 0.08 | 0.1421s\n",
            "==========Epoch: 51==========\n",
            "Loss 0.05 | 0.1850s\n",
            "Loss 0.08 | 0.1378s\n",
            "==========Epoch: 52==========\n",
            "Loss 0.05 | 0.2002s\n",
            "Loss 0.07 | 0.1375s\n",
            "==========Epoch: 53==========\n",
            "Loss 0.05 | 0.1826s\n",
            "Loss 0.07 | 0.1370s\n",
            "==========Epoch: 54==========\n",
            "Loss 0.05 | 0.1821s\n",
            "Loss 0.07 | 0.1355s\n",
            "==========Epoch: 55==========\n",
            "Loss 0.05 | 0.2035s\n",
            "Loss 0.07 | 0.1309s\n",
            "==========Epoch: 56==========\n",
            "Loss 0.04 | 0.1892s\n",
            "Loss 0.07 | 0.1343s\n",
            "==========Epoch: 57==========\n",
            "Loss 0.04 | 0.1807s\n",
            "Loss 0.07 | 0.1418s\n",
            "==========Epoch: 58==========\n",
            "Loss 0.04 | 0.1888s\n",
            "Loss 0.07 | 0.1331s\n",
            "==========Epoch: 59==========\n",
            "Loss 0.04 | 0.1839s\n",
            "Loss 0.07 | 0.1438s\n",
            "==========Epoch: 60==========\n",
            "Loss 0.05 | 0.1811s\n",
            "Loss 0.07 | 0.1390s\n",
            "==========Epoch: 61==========\n",
            "Loss 0.05 | 0.1889s\n",
            "Loss 0.07 | 0.1354s\n",
            "==========Epoch: 62==========\n",
            "Loss 0.04 | 0.1874s\n",
            "Loss 0.06 | 0.1386s\n",
            "==========Epoch: 63==========\n",
            "Loss 0.04 | 0.1810s\n",
            "Loss 0.06 | 0.1354s\n",
            "==========Epoch: 64==========\n",
            "Loss 0.04 | 0.1873s\n",
            "Loss 0.06 | 0.1368s\n",
            "==========Epoch: 65==========\n",
            "Loss 0.04 | 0.1812s\n",
            "Loss 0.06 | 0.1420s\n",
            "==========Epoch: 66==========\n",
            "Loss 0.04 | 0.1816s\n",
            "Loss 0.06 | 0.1393s\n",
            "==========Epoch: 67==========\n",
            "Loss 0.04 | 0.1809s\n",
            "Loss 0.06 | 0.1319s\n",
            "==========Epoch: 68==========\n",
            "Loss 0.04 | 0.1894s\n",
            "Loss 0.06 | 0.1397s\n",
            "==========Epoch: 69==========\n",
            "Loss 0.04 | 0.1840s\n",
            "Loss 0.06 | 0.1373s\n",
            "==========Epoch: 70==========\n",
            "Loss 0.04 | 0.1856s\n",
            "Loss 0.06 | 0.1352s\n",
            "==========Epoch: 71==========\n",
            "Loss 0.04 | 0.1791s\n",
            "Loss 0.06 | 0.1394s\n",
            "==========Epoch: 72==========\n",
            "Loss 0.04 | 0.1784s\n",
            "Loss 0.05 | 0.1386s\n",
            "==========Epoch: 73==========\n",
            "Loss 0.04 | 0.1906s\n",
            "Loss 0.05 | 0.1320s\n",
            "==========Epoch: 74==========\n",
            "Loss 0.04 | 0.1844s\n",
            "Loss 0.05 | 0.1346s\n",
            "==========Epoch: 75==========\n",
            "Loss 0.04 | 0.1917s\n",
            "Loss 0.05 | 0.1362s\n",
            "==========Epoch: 76==========\n",
            "Loss 0.04 | 0.1860s\n",
            "Loss 0.05 | 0.1311s\n",
            "==========Epoch: 77==========\n",
            "Loss 0.03 | 0.1842s\n",
            "Loss 0.05 | 0.1385s\n",
            "==========Epoch: 78==========\n",
            "Loss 0.03 | 0.1964s\n",
            "Loss 0.05 | 0.1411s\n",
            "==========Epoch: 79==========\n",
            "Loss 0.04 | 0.1819s\n",
            "Loss 0.05 | 0.1388s\n",
            "==========Epoch: 80==========\n",
            "Loss 0.04 | 0.2045s\n",
            "Loss 0.05 | 0.1319s\n",
            "==========Epoch: 81==========\n",
            "Loss 0.04 | 0.1933s\n",
            "Loss 0.05 | 0.1341s\n",
            "==========Epoch: 82==========\n",
            "Loss 0.03 | 0.1916s\n",
            "Loss 0.05 | 0.1472s\n",
            "==========Epoch: 83==========\n",
            "Loss 0.04 | 0.1843s\n",
            "Loss 0.05 | 0.1360s\n",
            "==========Epoch: 84==========\n",
            "Loss 0.03 | 0.1826s\n",
            "Loss 0.05 | 0.1351s\n",
            "==========Epoch: 85==========\n",
            "Loss 0.03 | 0.1851s\n",
            "Loss 0.05 | 0.1474s\n",
            "==========Epoch: 86==========\n",
            "Loss 0.03 | 0.1943s\n",
            "Loss 0.05 | 0.1359s\n",
            "==========Epoch: 87==========\n",
            "Loss 0.03 | 0.1839s\n",
            "Loss 0.04 | 0.1358s\n",
            "==========Epoch: 88==========\n",
            "Loss 0.03 | 0.1831s\n",
            "Loss 0.04 | 0.1407s\n",
            "==========Epoch: 89==========\n",
            "Loss 0.03 | 0.1878s\n",
            "Loss 0.04 | 0.1347s\n",
            "==========Epoch: 90==========\n",
            "Loss 0.03 | 0.1820s\n",
            "Loss 0.04 | 0.1360s\n",
            "==========Epoch: 91==========\n",
            "Loss 0.03 | 0.1992s\n",
            "Loss 0.04 | 0.1415s\n",
            "==========Epoch: 92==========\n",
            "Loss 0.03 | 0.1871s\n",
            "Loss 0.04 | 0.1377s\n",
            "==========Epoch: 93==========\n",
            "Loss 0.03 | 0.1901s\n",
            "Loss 0.04 | 0.1383s\n",
            "==========Epoch: 94==========\n",
            "Loss 0.03 | 0.1877s\n",
            "Loss 0.04 | 0.1348s\n",
            "==========Epoch: 95==========\n",
            "Loss 0.03 | 0.1908s\n",
            "Loss 0.04 | 0.1318s\n",
            "==========Epoch: 96==========\n",
            "Loss 0.03 | 0.1902s\n",
            "Loss 0.04 | 0.1338s\n",
            "==========Epoch: 97==========\n",
            "Loss 0.03 | 0.1901s\n",
            "Loss 0.04 | 0.1346s\n",
            "==========Epoch: 98==========\n",
            "Loss 0.03 | 0.1870s\n",
            "Loss 0.04 | 0.1319s\n",
            "==========Epoch: 99==========\n",
            "Loss 0.03 | 0.1794s\n",
            "Loss 0.04 | 0.1382s\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(max_epochs):\n",
        "    print(\"=\" * 10 + f\"Epoch: {epoch}\" + \"=\" * 10)\n",
        "    epoch_loss = train_epoch(model, train_dl, opt, criterion)\n",
        "    val_loss, rmse = eval_epoch(model, test_dl, criterion)\n",
        "    losses.extend(epoch_loss)\n",
        "    val_losses.extend(val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "aWrFCe8KNORw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "aWrFCe8KNORw",
        "outputId": "e73a1cd3-5d05-47f3-ae67-3bd7361b1e09"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(losses)\n",
        "plt.plot(val_losses)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "6e1Qg2LjxZUV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e1Qg2LjxZUV",
        "outputId": "8d8ffc07-9edc-46db-f418-01e54d74c741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss 0.04 | 0.1539s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9555803537368774"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_loss, rmse = eval_epoch(model, test_dl, criterion)\n",
        "rmse"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AutoRec custom model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "8acda9f5fdb612953975aee10444884cfb48234c8fe5ff7f806137c25a4f468b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
