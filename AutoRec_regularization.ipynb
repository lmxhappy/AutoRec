{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0jM2Mq4akyFG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jM2Mq4akyFG",
    "outputId": "478a2e75-cce9-439f-8bfa-035a5996e30f"
   },
   "outputs": [],
   "source": [
    "# !pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3GbcZ0PAkoc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GbcZ0PAkoc6",
    "outputId": "23145b8c-a289-44eb-ea9d-df40547a834f"
   },
   "outputs": [],
   "source": [
    "# !wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# !unzip ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aadb06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata import datapipes as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca85530-54da-4a45-bf76-18549c7bc18b",
   "metadata": {
    "id": "3ca85530-54da-4a45-bf76-18549c7bc18b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, div, square, norm\n",
    "from torch.nn import functional as F\n",
    "from torchdata import datapipes as dp\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa37b148-81c0-4c5f-8f91-5c826a2e1132",
   "metadata": {
    "id": "fa37b148-81c0-4c5f-8f91-5c826a2e1132"
   },
   "outputs": [],
   "source": [
    "datapath = 'ml-1m/'\n",
    "seed = 12\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432aa6bd-69e6-49bc-be63-e2b2f131cc2f",
   "metadata": {
    "id": "432aa6bd-69e6-49bc-be63-e2b2f131cc2f"
   },
   "outputs": [],
   "source": [
    "num_users = pd.read_csv(datapath + 'users.dat',\n",
    "            delimiter='::',\n",
    "            engine='python',\n",
    "            encoding='latin-1',\n",
    "            header=None)[0].max()\n",
    "num_items = pd.read_csv(datapath + 'movies.dat',\n",
    "            delimiter='::',\n",
    "            engine='python',\n",
    "            encoding='latin-1',\n",
    "            header=None)[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc1f682-19c6-4958-8c24-c320138b3c38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adc1f682-19c6-4958-8c24-c320138b3c38",
    "outputId": "b52fcc07-aa6a-413a-99ad-da263fe077f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "841c738c-bc2f-4203-9c3a-e21b4aaa271c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "841c738c-bc2f-4203-9c3a-e21b4aaa271c",
    "outputId": "a5351bff-24e4-4b43-82b5-264d3d2ce8b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3161]), torch.Size([791]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items, test_items = train_test_split(torch.arange(num_items),\n",
    "                                           test_size=0.2,\n",
    "                                           random_state=seed)\n",
    "train_items.size(), test_items.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb081cd-a018-4171-8dee-27f91be9ae0e",
   "metadata": {
    "id": "5eb081cd-a018-4171-8dee-27f91be9ae0e"
   },
   "outputs": [],
   "source": [
    "# create global user_item matrix and mask matrix\n",
    "user_item_mat = torch.zeros((num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb1e617-274f-44c2-9e3b-5a9e445fed60",
   "metadata": {
    "id": "6cb1e617-274f-44c2-9e3b-5a9e445fed60"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(datapath + 'ratings.dat',\n",
    "            encoding='latin-1',\n",
    "            header=None,\n",
    "            engine='python',\n",
    "            delimiter='::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbfe69d5-876f-470b-baaa-c715b0ed7f1f",
   "metadata": {
    "id": "dbfe69d5-876f-470b-baaa-c715b0ed7f1f"
   },
   "outputs": [],
   "source": [
    "def create_data_from_line(line):\n",
    "    user_id, item_id, rating, *_ = line\n",
    "    user_item_mat[user_id - 1, item_id - 1] = rating\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f1c70c-4faf-4333-9ce3-4edae844a7c1",
   "metadata": {
    "id": "f1f1c70c-4faf-4333-9ce3-4edae844a7c1"
   },
   "outputs": [],
   "source": [
    "ratings.T.apply(create_data_from_line);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8908844-5f9a-415f-9b15-d1330c8abdae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8908844-5f9a-415f-9b15-d1330c8abdae",
    "outputId": "7bc4e468-4700-4c19-ce7c-67be62296a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9581)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(user_item_mat == 0, 1, 0).sum() / (num_users * num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d1b5e0b-614b-43a9-b536-cad62642a39a",
   "metadata": {
    "id": "2d1b5e0b-614b-43a9-b536-cad62642a39a"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return torch.LongTensor(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85b6d39-3de5-42fd-a7e5-c31f0542321a",
   "metadata": {
    "id": "b85b6d39-3de5-42fd-a7e5-c31f0542321a"
   },
   "outputs": [],
   "source": [
    "def create_datapipe_from_array(array, mode='train', batch_size=32, len=1000):\n",
    "    pipes = dp.iter.IterableWrapper(array)\n",
    "    pipes = pipes.shuffle(buffer_size=len)\n",
    "    pipes = pipes.sharding_filter()\n",
    "    \n",
    "    if mode == 'train':\n",
    "        pipes = pipes.batch(batch_size, drop_last=True)\n",
    "    else:\n",
    "        pipes = pipes.batch(batch_size)\n",
    "    \n",
    "    pipes = pipes.map(collate_fn)\n",
    "    return pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4466bc0-38bb-49ae-b5b9-8599aa3b93af",
   "metadata": {
    "id": "f4466bc0-38bb-49ae-b5b9-8599aa3b93af"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_dp = create_datapipe_from_array(train_items, batch_size=batch_size)\n",
    "test_dp = create_datapipe_from_array(test_items, mode='test', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c39eebc-f565-401e-b28f-eed5b07a2877",
   "metadata": {
    "id": "3c39eebc-f565-401e-b28f-eed5b07a2877"
   },
   "outputs": [],
   "source": [
    "num_workers = 2\n",
    "\n",
    "train_dl = DataLoader(dataset=train_dp, shuffle=True, num_workers=num_workers)\n",
    "test_dl = DataLoader(dataset=test_dp, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "680914e1-62ca-4ca5-b7c8-55c3f2fbf5fa",
   "metadata": {
    "id": "680914e1-62ca-4ca5-b7c8-55c3f2fbf5fa"
   },
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, d, k, lambda_):\n",
    "        super().__init__()\n",
    "        self.lambda_ = lambda_\n",
    "        self.W = nn.Parameter(torch.randn(d, k))\n",
    "        self.V = nn.Parameter(torch.randn(k, d))\n",
    "        self.mu = nn.Parameter(torch.randn(k))\n",
    "        self.b = nn.Parameter(torch.randn(d))\n",
    "    \n",
    "    def regularization(self):\n",
    "        return div(self.lambda_, 2) * (square(norm(self.W)) + square(norm(self.V)))\n",
    "    \n",
    "    def forward(self, r):\n",
    "        encoder = self.V.matmul(r.T).T + self.mu\n",
    "        return self.W.matmul(encoder.sigmoid().T).T + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44c533de-1f35-435d-abf4-92d8b2b66fea",
   "metadata": {
    "id": "44c533de-1f35-435d-abf4-92d8b2b66fea"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dl, opt, criterion):\n",
    "    list_loss = []\n",
    "    start_time = time.perf_counter()\n",
    "    for batch_idx, items_idx in enumerate(dl):\n",
    "        r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device)\n",
    "        r_hat = model(r)\n",
    "        loss = criterion(r, r_hat * torch.sign(r)) + model.regularization()\n",
    "        \n",
    "        list_loss.append(loss.item())\n",
    "        if batch_idx % 50 == 0:\n",
    "            log_time = round(time.perf_counter() - start_time, 4)\n",
    "            print(\"Loss {:.2f} | {:.4f}s\".format(loss.item(), log_time))\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return list_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cab2f4a-52d2-4681-a6c8-6d7699084c41",
   "metadata": {
    "id": "9cab2f4a-52d2-4681-a6c8-6d7699084c41"
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, dl, criterion):\n",
    "    model.eval()\n",
    "    truth = []\n",
    "    predict = []\n",
    "    list_loss = []\n",
    "    start_time = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, items_idx in enumerate(dl):\n",
    "            r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device)\n",
    "\n",
    "            r_hat = model(r)\n",
    "\n",
    "            truth.append(r)\n",
    "            predict.append(r_hat * torch.sign(r))\n",
    "\n",
    "            loss = criterion(r, r_hat * torch.sign(r)) + model.regularization()\n",
    "\n",
    "            list_loss.append(loss.item())\n",
    "            if batch_idx % 30 == 0:\n",
    "                log_time = round(time.perf_counter() - start_time, 4)\n",
    "                print(\"Loss {:.2f} | {:.4f}s\".format(loss.item(), log_time))\n",
    "\n",
    "    rmse = torch.Tensor([torch.sqrt(square(r - r_hat).sum() / torch.sign(r).sum())\n",
    "                            for r, r_hat in zip(truth, predict)]).mean().item()\n",
    "\n",
    "    return list_loss, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d42ef645-20e3-4419-aadb-68125fc6acf4",
   "metadata": {
    "id": "d42ef645-20e3-4419-aadb-68125fc6acf4"
   },
   "outputs": [],
   "source": [
    "model = AutoRec(d=num_users, k=500, lambda_=0.0001).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.012, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1-EWBorMNCz",
   "metadata": {
    "id": "c1-EWBorMNCz"
   },
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3802be9b-add0-463c-afac-e9657fd43076",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3802be9b-add0-463c-afac-e9657fd43076",
    "outputId": "c019ff75-ad5b-4580-91e1-bbd314b3f9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Epoch: 0==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/conan/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/conan/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/conan/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py\", line 331, in __setstate__\n",
      "    self._datapipe = pickle.loads(value)\n",
      "AttributeError: Can't get attribute 'collate_fn' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/conan/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/conan/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/conan/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py\", line 331, in __setstate__\n",
      "    self._datapipe = pickle.loads(value)\n",
      "AttributeError: Can't get attribute 'collate_fn' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 85023, 85024) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 85023) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epochs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     val_loss, rmse \u001b[38;5;241m=\u001b[39m eval_epoch(model, test_dl, criterion)\n\u001b[1;32m      5\u001b[0m     losses\u001b[38;5;241m.\u001b[39mextend(epoch_loss)\n",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dl, opt, criterion)\u001b[0m\n\u001b[1;32m      2\u001b[0m list_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, items_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dl):\n\u001b[1;32m      5\u001b[0m     r \u001b[38;5;241m=\u001b[39m user_item_mat[:, items_idx]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     r_hat \u001b[38;5;241m=\u001b[39m model(r)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38-torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1176\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1175\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 85023, 85024) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"=\" * 10 + f\"Epoch: {epoch}\" + \"=\" * 10)\n",
    "    epoch_loss = train_epoch(model, train_dl, opt, criterion)\n",
    "    val_loss, rmse = eval_epoch(model, test_dl, criterion)\n",
    "    losses.extend(epoch_loss)\n",
    "    val_losses.extend(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aWrFCe8KNORw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "aWrFCe8KNORw",
    "outputId": "386bbbce-33c6-4bb6-9d1f-447c0fc78680"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1Qg2LjxZUV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e1Qg2LjxZUV",
    "outputId": "32374698-c927-4d8b-8f06-0b782bd1eb4a"
   },
   "outputs": [],
   "source": [
    "val_loss, rmse = eval_epoch(model, test_dl, criterion)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3PbFHClaYxlj",
   "metadata": {
    "id": "3PbFHClaYxlj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AutoRec_regularization.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
